## Nginx
nignx是什么？优点？  
https://www.cnblogs.com/xiohao/p/6433401.html  

反向代理  
好吧，之前我也为这个问题纠结挺久，为什么叫反向？既然有反向，那肯定有正向，现有客户端x，代理服务器y，最终服务器z，现在x直接访问z：x->z，通过代理服务器y：x->y->z，无论正反代理服务器y都是位于x、z之间，正反是根据代理服务器代理的是谁来判断的  
正向：**代理服务器y代理的是客户端**，站在客户端的角度上是正向的，所以是正向代理  
反向：**代理服务器y代理的是最终服务器z**，站在客户端的角度上是反向的，所以是反向代理  
好吧，这是我的理解，可能不够详细，这里给大家推荐一片文章，介绍的挺好的：http://bbs.51cto.com/thread-967852-1-1.html    

nginx高性能的原因：得益于它的事件处理机制，**异步非阻塞事件处理机制**：运用了epoll模型，提供了一个队列，排队解决。  

Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。所以才使得Nginx支持更高的并发。

#负载均衡
负载均衡即是代理服务器将接收的请求均衡的分发到各服务器中。  
负载均衡主要解决网络拥塞问题，提高服务器响应速度，服务就近提供，达到更好的访问质量，减少后台服务器大并发压力

# Ngnix的几种负载均衡算法
**1.轮循（默认）**

	每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，则自动剔除故障机器，使用户访问不受影响。
**2.weight**

	指定轮询权重，weight值越大，分配到的几率就越高，主要用于后端每台服务器性能不均衡的情况。
**3.ip_hash**

	每个请求按访问IP的哈希结果分配，这样每个访客固定访问一个后端服务器，可以有效的解决动态网页存在的session共享问题。  
	但它本身也存在缺陷：  
	1）nginx不是最前端的服务器：ip_hash要求nginx一定是最前端的服务器，否则nginx得不到正确ip，就不能根据ip作hash。譬如使用的是squid（缓冲服务器和代理服务器，有效提高响应	时间为最前端，那么nginx取ip时只能得到squid的服务器ip地址，用这个地址来作分流是肯定错乱的。  
	2）nginx的后端还有其它方式的负载均衡：假如nginx后端又有其它负载均衡，将请求又通过另外的方式分流了，那么某个客户端的请求肯定不能定位到同一台session应用服务器上。  
	3）多个外网出口：很多公司上网有多个出口，多个ip地址，用户访问互联网时候自动切换ip。而且这种情况不在少数。使用 ip_hash 的话对这种情况的用户无效，无法将某个用户绑定在固定的	tomcat上 。
**4.fair（第三方）**

	更智能的一个负载均衡算法，此算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。如果想要使用此调度算法，需要Nginx的upstream_fair模块。
**5.url_hash（第三方）**

	按访问URL的哈希结果来分配请求，使每个URL定向到同一台后端服务器，可以进一步提高后端缓存服务器的效率。如果想要使用此调度算法，需要Nginx的hash软件包。
	
upsteam：用来定义服务器组的模块。upstream中的server用来指定一个服务器。  
**1.weight**:表示权重，权重越大，表示被访问的概率越大

	server 192.168.18.201 weight=4;
**2.max_fails**：表示连接失败重新连接的最多次数

	server 192.168.18.202 max_fails=3;
**3.fail_timeout**:连接超时的时间(即多久算连接失败)

	server 192.168.18.202 max_fails=3 fail_timeout=20s;
**4.backup:**标记一台服务器作为备用服务器(它只在其他服务器繁忙的时候工作)

	server 192.168.18.203 backup;
**5.down:**标记一台服务器下线或者暂时不可用

	server 192.168.18.203 down;
**6.max_conns:**表示指定的服务器最大连接数限制(nginx1.5.9以上版本才有的参数)

	server 192.168.18.202 max_conns=1024;

nginx负载的效率：
Nignx负载均衡功能是通过upstream模块实现的，是基于内容和应用的7层交换负载均衡。Nginx负载均衡默认对后端服务器有健康检测能力，但是检测能力较弱，仅限于端口检测，在后端服务器比较少的情况下（10台及以下）负载均衡能力表现突出。与LVS负载均衡相比，LVS是基于四层的IP负载均衡技术，具有高性能、高可用、吞吐量大等优点，LVS在集群中表现更佳。

## 动静分离
动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问。   
这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中。
	
	location /ncwx-frontend-media {
       alias   D:\\lxnc\\images;
   }

## nginx 和 lvs 的区别
抗负载能力强，因为lvs工作方式的逻辑是非常简单的，而且工作再网络层第4层，仅作请求分发用，没有流量，所以在效率上基本不需要太过考虑。lvs一般很少出现故障。无流量，lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。lvs基本上能支持所有应用，因为绿色工作在第4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等。

## nginx 进程和线程
nginx默认以多进程的方式工作,一个master进程和多个worker进程,master进程主要用来管理worker进程.多个worker进程同等竞争来自客户端的请求,一个worker进程可以处理多个请求,但不能处理其它worker进程的请求.每个worker进程里面只有一个主线程,在epoll支持下,采用异步非阻塞的方式来处理请求,从而实现高并发.epoll支持监听多个事件(socket轮询),当事件没准备好时,放到epoll里面,事件准备好了,就去读写.与多线程相比,这种事件处理方式是有很大的优势的,不需要创建线程,每个请求占用的内存也很少,没有上下文切换,事件处理非常的轻量级.并发数再多也不会导致无谓的资源浪费(上下文切换),更多的并发数,只是会占用更多的内存而已.而httpd常用的工作方式是每个请求会独占一个工作线程,当并发数上到几千时，就同时有几千的线程在处理请求了,这对操作系统来说,是个不小的挑战.线程带来的内存占用非常大,线程的上下文切换带来的cpu开销很大,httpd的性能自然就上不去了.Tengine团队之前有对连接数进行过测试,在24G内存的机器上,Nginx处理的并发请求数达到过200万.(平均1G内存可以处理8万多请求)Nginx支持将某一个进程绑定在某一个核上(CPU亲缘性绑定),这样就不会因为进程的切换带来cache的失效,所以推荐设置cpu有几个核就设置几个worker进程.但注意,过多的worker进程,只会导致进程来竞争cpu资源了,从而带来不必要的上下文切换,所以worker进程不是越多越好.详细参见:
http://tengine.taobao.org/book/chapter_02.html